# configs/inference/vitg-384/rvsp/echojepa_224px.yaml
# INFERENCE CONFIG
app: vjepa
cpus_per_task: 32
# Output folder for inference logs (separate from training to avoid overwrite)
folder: /home/sagemaker-user/user-default-efs/vjepa2/evals/vitg-384/rvsp_inference
mem_per_gpu: 80G
nodes: 1
tasks_per_node: 8
num_workers: 8

# Use the same evaluation infrastructure
eval_name: video_classification_frozen_multi
resume_checkpoint: true # <--- CHANGE THIS TO TRUE, OTHERWISE RANDOM WEIGHTS
# Use a new tag for inference results
tag: rvsp-echojepa-224px-test

# --- CRITICAL INFERENCE SETTINGS ---
val_only: true
# Path where the predictions CSV will be saved
predictions_save_path: /home/sagemaker-user/user-default-efs/vjepa2/preds/echojepa_224px_test_predictions.csv

# POINT THIS TO YOUR TRAINED PROBE CHECKPOINT
probe_checkpoint: /home/sagemaker-user/user-default-efs/vjepa2/checkpoints/eval_probes/rvsp/echojepa_224px.pt

experiment:
  classifier:
    task_type: regression      # NEW: Specify regression task  
    num_heads: 16           # changed from 16 / <-- must divide 1408 (ViT-G). Valid: 16, 22, 32, 44...
    num_probe_blocks: 4     # changed from 4
    num_views: 2
    clips_per_view: 2
    use_factorized: true
    num_targets: 1            # CHANGED: Replace num_classes with num_targets 

    use_slot_embeddings: true   # default false keeps old behavior
    use_late_fusion: false

  data:
    dataset_type: VideoGroupDataset
    # Point 'dataset_val' to your TEST CSV
    dataset_val:   /home/sagemaker-user/user-default-efs/vjepa2/data/csv/rvsp_test.csv
    # Train path is ignored in val_only mode, but usually required by config parser
    dataset_train: /home/sagemaker-user/user-default-efs/vjepa2/data/csv/rvsp_test.csv 
    
    num_classes: 1           # IMPORTANT: 1 for regression
    resolution: 224 
    frames_per_clip: 16      # change to 32 to match anneal, 16 to match pretrain
    frame_step: 1            # change to 2 --> ~1.28 s coverage on ~50 fps; use step:1 (~0.64 s) if you want tighter windows; original fpc16xfs3=48
    num_segments: 2          # Number of videos per group  
    num_clips_per_video: 2   # Number of clips from each video 
    num_views_per_segment: 1 # one spatial crop (reduce stochasticity); for echoâ€”spatial variation is low; temporal coverage more 

    target_mean: 34.4650
    target_std: 14.0130

  optimization:
    # You can increase batch size for inference since gradients are off
    batch_size: 4
    
    # Zero out learning rates for safety (though val_only prevents updates anyway)
    multihead_kwargs:
    - final_lr: 0.0
      final_weight_decay: 0.0
      lr: 0.0
      start_lr: 0.0
      warmup: 0.0
      weight_decay: 0.0

    num_epochs: 1 # Run once
    use_bfloat16: true
    use_pos_embed: false

model_kwargs:
  # Keep identical to training
  checkpoint: "/home/sagemaker-user/user-default-efs/vjepa2/checkpoints/anneal/keep/pt-280-an81.pt"
  module_name: evals.video_classification_frozen_multi.modelcustom.vit_encoder_multiclip
  
  pretrain_kwargs:
    encoder:
      checkpoint_key: target_encoder
      img_temporal_dim_size: null
      model_name: vit_giant_xformers
      patch_size: 16
      tubelet_size: 2
      uniform_power: true
      use_rope: true
      
  wrapper_kwargs:
    max_frames: 128
    use_pos_embed: false
    return_per_clip: true   # ADDED - must match training!